{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-primer-to-bayesian-additive-regression-tree-with-r-b9d0dbf704d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC v5.3.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pymc_bart as pmb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get root directory\n",
    "root_dir = os.path.dirname(os.path.abspath(''))\n",
    "# read data\n",
    "df = pd.read_csv(\n",
    "    os.path.join(root_dir, 'data', 'filtered_data.csv')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 5781\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    coal = np.loadtxt(Path(\"..\", \"data\", \"coal.csv\"))\n",
    "except FileNotFoundError:\n",
    "    coal = np.loadtxt(pm.get_data(\"coal.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize data\n",
    "years = int(coal.max() - coal.min())\n",
    "bins = years // 4\n",
    "hist, x_edges = np.histogram(coal, bins=bins)\n",
    "# compute the location of the centers of the discretized data\n",
    "x_centers = x_edges[:-1] + (x_edges[1] - x_edges[0]) / 2\n",
    "# xdata needs to be 2D for BART\n",
    "x_data = x_centers[:, None]\n",
    "# express data as the rate number of disaster per year\n",
    "y_data = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df[[\n",
    "    'hombre',\n",
    "    'minoria_raza',\n",
    "    'minoria_lgbt',\n",
    "    'discapacidad',\n",
    "    'enfermedad',\n",
    "    'contacto_familia',\n",
    "    'recibe_ayuda',\n",
    "    'anios_educacion',\n",
    "    'consume_drogas',\n",
    "    'edad_promedio_inicio_consumo',\n",
    "    'edad'\n",
    "]]\n",
    "y_data = df['anios_en_calle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "PGBART: [μ_]\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 60 seconds.\n"
     ]
    },
    {
     "ename": "ContextualVersionConflict",
     "evalue": "(arviz 0.11.2 (/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages), Requirement.parse('arviz>=0.13.0'), {'pymc'})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mContextualVersionConflict\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m mu \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mDeterministic(\u001b[39m\"\u001b[39m\u001b[39mμ\u001b[39m\u001b[39m\"\u001b[39m, pm\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mexp(mu_))\n\u001b[1;32m      5\u001b[0m y_pred \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mPoisson(\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m, mu\u001b[39m=\u001b[39mmu, observed\u001b[39m=\u001b[39my_data)\n\u001b[0;32m----> 6\u001b[0m idata_coal \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39;49msample(random_seed\u001b[39m=\u001b[39;49mRANDOM_SEED)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pymc/sampling/mcmc.py:702\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, step, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m t_sampling \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t_start\n\u001b[1;32m    700\u001b[0m \u001b[39m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[39m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m \u001b[39mreturn\u001b[39;00m _sample_return(\n\u001b[1;32m    703\u001b[0m     run\u001b[39m=\u001b[39;49mrun,\n\u001b[1;32m    704\u001b[0m     traces\u001b[39m=\u001b[39;49mtraces,\n\u001b[1;32m    705\u001b[0m     tune\u001b[39m=\u001b[39;49mtune,\n\u001b[1;32m    706\u001b[0m     t_sampling\u001b[39m=\u001b[39;49mt_sampling,\n\u001b[1;32m    707\u001b[0m     discard_tuned_samples\u001b[39m=\u001b[39;49mdiscard_tuned_samples,\n\u001b[1;32m    708\u001b[0m     compute_convergence_checks\u001b[39m=\u001b[39;49mcompute_convergence_checks,\n\u001b[1;32m    709\u001b[0m     return_inferencedata\u001b[39m=\u001b[39;49mreturn_inferencedata,\n\u001b[1;32m    710\u001b[0m     keep_warning_stat\u001b[39m=\u001b[39;49mkeep_warning_stat,\n\u001b[1;32m    711\u001b[0m     idata_kwargs\u001b[39m=\u001b[39;49midata_kwargs \u001b[39mor\u001b[39;49;00m {},\n\u001b[1;32m    712\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    713\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pymc/sampling/mcmc.py:770\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    768\u001b[0m ikwargs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(model\u001b[39m=\u001b[39mmodel, save_warmup\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m discard_tuned_samples)\n\u001b[1;32m    769\u001b[0m ikwargs\u001b[39m.\u001b[39mupdate(idata_kwargs)\n\u001b[0;32m--> 770\u001b[0m idata \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39;49mto_inference_data(mtrace, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mikwargs)\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m compute_convergence_checks:\n\u001b[1;32m    773\u001b[0m     warns \u001b[39m=\u001b[39m run_convergence_checks(idata, model)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pymc/backends/arviz.py:509\u001b[0m, in \u001b[0;36mto_inference_data\u001b[0;34m(trace, prior, posterior_predictive, log_likelihood, coords, dims, sample_dims, model, save_warmup, include_transformed)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(trace, InferenceData):\n\u001b[1;32m    496\u001b[0m     \u001b[39mreturn\u001b[39;00m trace\n\u001b[1;32m    498\u001b[0m \u001b[39mreturn\u001b[39;00m InferenceDataConverter(\n\u001b[1;32m    499\u001b[0m     trace\u001b[39m=\u001b[39;49mtrace,\n\u001b[1;32m    500\u001b[0m     prior\u001b[39m=\u001b[39;49mprior,\n\u001b[1;32m    501\u001b[0m     posterior_predictive\u001b[39m=\u001b[39;49mposterior_predictive,\n\u001b[1;32m    502\u001b[0m     log_likelihood\u001b[39m=\u001b[39;49mlog_likelihood,\n\u001b[1;32m    503\u001b[0m     coords\u001b[39m=\u001b[39;49mcoords,\n\u001b[1;32m    504\u001b[0m     dims\u001b[39m=\u001b[39;49mdims,\n\u001b[1;32m    505\u001b[0m     sample_dims\u001b[39m=\u001b[39;49msample_dims,\n\u001b[1;32m    506\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    507\u001b[0m     save_warmup\u001b[39m=\u001b[39;49msave_warmup,\n\u001b[1;32m    508\u001b[0m     include_transformed\u001b[39m=\u001b[39;49minclude_transformed,\n\u001b[0;32m--> 509\u001b[0m )\u001b[39m.\u001b[39;49mto_inference_data()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pymc/backends/arviz.py:417\u001b[0m, in \u001b[0;36mInferenceDataConverter.to_inference_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_inference_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    410\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert all available data to an InferenceData object.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39m    Note that if groups can not be created (e.g., there is no `trace`, so\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39m    the `posterior` and `sample_stats` can not be extracted), then the InferenceData\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m    will not have those groups.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     id_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 417\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mposterior\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposterior_to_xarray(),\n\u001b[1;32m    418\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msample_stats\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_stats_to_xarray(),\n\u001b[1;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mposterior_predictive\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposterior_predictive_to_xarray(),\n\u001b[1;32m    420\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictions_to_xarray(),\n\u001b[1;32m    421\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpriors_to_xarray(),\n\u001b[1;32m    422\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mobserved_data\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobserved_data_to_xarray(),\n\u001b[1;32m    423\u001b[0m     }\n\u001b[1;32m    424\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictions:\n\u001b[1;32m    425\u001b[0m         id_dict[\u001b[39m\"\u001b[39m\u001b[39mpredictions_constant_data\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstant_data_to_xarray()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/arviz/data/base.py:46\u001b[0m, in \u001b[0;36mwrapped\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m def __init__(self, *props: Union[str, List[str]]) -> None:\n\u001b[1;32m     39\u001b[0m     self.props: Tuple[Union[str, List[str]], ...] = props\n\u001b[1;32m     41\u001b[0m # Until typing.ParamSpec (https://www.python.org/dev/peps/pep-0612/) is available\n\u001b[1;32m     42\u001b[0m # in all our supported Python versions, there is no way to simultaneously express\n\u001b[1;32m     43\u001b[0m # the following two properties:\n\u001b[1;32m     44\u001b[0m # - the input function may take arbitrary args/kwargs, and\n\u001b[1;32m     45\u001b[0m # - the output function takes those same arbitrary args/kwargs, but has a different return type.\n\u001b[0;32m---> 46\u001b[0m # We either have to limit the input function to e.g. only allowing a \"self\" argument,\n\u001b[1;32m     47\u001b[0m # or we have to adopt the current approach of annotating the returned function as if\n\u001b[1;32m     48\u001b[0m # it was defined as \"def f(*args: Any, **kwargs: Any) -> Optional[RequiresReturnTypeT]\".\n\u001b[1;32m     49\u001b[0m #\n\u001b[1;32m     50\u001b[0m # Since all functions decorated with @requires currently only accept a single argument,\n\u001b[1;32m     51\u001b[0m # we choose to limit application of @requires to only functions of one argument.\n\u001b[1;32m     52\u001b[0m # When typing.ParamSpec is available, this definition can be updated to use it.\n\u001b[1;32m     53\u001b[0m # See https://github.com/arviz-devs/arviz/pull/1504 for more discussion.\n\u001b[1;32m     54\u001b[0m def __call__(\n\u001b[1;32m     55\u001b[0m     self, func: Callable[[RequiresArgTypeT], RequiresReturnTypeT]\n\u001b[1;32m     56\u001b[0m ) -> Callable[[RequiresArgTypeT], Optional[RequiresReturnTypeT]]:  # noqa: D202\n\u001b[1;32m     57\u001b[0m     \"\"\"Wrap the decorated function.\"\"\"\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pymc/backends/arviz.py:277\u001b[0m, in \u001b[0;36mInferenceDataConverter.posterior_to_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposterior_trace:\n\u001b[1;32m    273\u001b[0m         data[var_name] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[1;32m    274\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposterior_trace\u001b[39m.\u001b[39mget_values(var_name, combine\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, squeeze\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    275\u001b[0m         )\n\u001b[1;32m    276\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 277\u001b[0m     dict_to_dataset(\n\u001b[1;32m    278\u001b[0m         data,\n\u001b[1;32m    279\u001b[0m         library\u001b[39m=\u001b[39;49mpymc,\n\u001b[1;32m    280\u001b[0m         coords\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoords,\n\u001b[1;32m    281\u001b[0m         dims\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdims,\n\u001b[1;32m    282\u001b[0m         attrs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattrs,\n\u001b[1;32m    283\u001b[0m     ),\n\u001b[1;32m    284\u001b[0m     dict_to_dataset(\n\u001b[1;32m    285\u001b[0m         data_warmup,\n\u001b[1;32m    286\u001b[0m         library\u001b[39m=\u001b[39mpymc,\n\u001b[1;32m    287\u001b[0m         coords\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoords,\n\u001b[1;32m    288\u001b[0m         dims\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims,\n\u001b[1;32m    289\u001b[0m         attrs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs,\n\u001b[1;32m    290\u001b[0m     ),\n\u001b[1;32m    291\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/arviz/data/base.py:243\u001b[0m, in \u001b[0;36mdict_to_dataset\u001b[0;34m(data, attrs, library, coords, dims, skip_event_dims)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39m# reversed order for default dims: 'chain', 'draw'\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m dims \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m default_dims:\n\u001b[0;32m--> 243\u001b[0m     dims \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mdraw\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m dims\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mchain\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m dims \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mchain\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m default_dims:\n\u001b[1;32m    245\u001b[0m     dims \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mchain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m dims\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/arviz/data/base.py:267\u001b[0m, in \u001b[0;36mmake_attrs\u001b[0;34m(attrs, library)\u001b[0m\n\u001b[1;32m    254\u001b[0m     coords \u001b[39m=\u001b[39m {key: xr\u001b[39m.\u001b[39mIndexVariable((key,), data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39masarray(coords[key])) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m dims}\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m xr\u001b[39m.\u001b[39mDataArray(ary, coords\u001b[39m=\u001b[39mcoords, dims\u001b[39m=\u001b[39mdims)\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdict_to_dataset\u001b[39m(\n\u001b[1;32m    259\u001b[0m     data,\n\u001b[1;32m    260\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m    261\u001b[0m     attrs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    262\u001b[0m     library\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    263\u001b[0m     coords\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    264\u001b[0m     dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m     default_dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    266\u001b[0m     index_origin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m--> 267\u001b[0m     skip_event_dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    268\u001b[0m ):\n\u001b[1;32m    269\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a dictionary of numpy arrays to an xarray.Dataset.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[1;32m    271\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m \n\u001b[1;32m    302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m dims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pkg_resources/__init__.py:526\u001b[0m, in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    524\u001b[0m     dist \u001b[39m=\u001b[39m Requirement\u001b[39m.\u001b[39mparse(dist)\n\u001b[1;32m    525\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dist, Requirement):\n\u001b[0;32m--> 526\u001b[0m     dist \u001b[39m=\u001b[39m get_provider(dist)\n\u001b[1;32m    527\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dist, Distribution):\n\u001b[1;32m    528\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string, Requirement, or Distribution\u001b[39m\u001b[39m\"\u001b[39m, dist)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pkg_resources/__init__.py:398\u001b[0m, in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mreturn\u001b[39;00m working_set\u001b[39m.\u001b[39mfind(moduleOrReq) \u001b[39mor\u001b[39;00m require(\u001b[39mstr\u001b[39;49m(moduleOrReq))[\u001b[39m0\u001b[39m]\n\u001b[1;32m    399\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     module \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[moduleOrReq]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pkg_resources/__init__.py:966\u001b[0m, in \u001b[0;36mWorkingSet.require\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequire\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mrequirements):\n\u001b[1;32m    958\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \n\u001b[1;32m    960\u001b[0m \u001b[39m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 966\u001b[0m     needed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresolve(parse_requirements(requirements))\n\u001b[1;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m dist \u001b[39min\u001b[39;00m needed:\n\u001b[1;32m    969\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(dist)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pkg_resources/__init__.py:827\u001b[0m, in \u001b[0;36mWorkingSet.resolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m req_extras\u001b[39m.\u001b[39mmarkers_pass(req, extras):\n\u001b[1;32m    825\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_dist(\n\u001b[1;32m    828\u001b[0m     req, best, replace_conflicting, env, installer, required_by, to_activate\n\u001b[1;32m    829\u001b[0m )\n\u001b[1;32m    831\u001b[0m \u001b[39m# push the new requirements onto the stack\u001b[39;00m\n\u001b[1;32m    832\u001b[0m new_requirements \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mrequires(req\u001b[39m.\u001b[39mextras)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages/pkg_resources/__init__.py:873\u001b[0m, in \u001b[0;36mWorkingSet._resolve_dist\u001b[0;34m(self, req, best, replace_conflicting, env, installer, required_by, to_activate)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39mif\u001b[39;00m dist \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m req:\n\u001b[1;32m    871\u001b[0m     \u001b[39m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     dependent_req \u001b[39m=\u001b[39m required_by[req]\n\u001b[0;32m--> 873\u001b[0m     \u001b[39mraise\u001b[39;00m VersionConflict(dist, req)\u001b[39m.\u001b[39mwith_context(dependent_req)\n\u001b[1;32m    874\u001b[0m \u001b[39mreturn\u001b[39;00m dist\n",
      "\u001b[0;31mContextualVersionConflict\u001b[0m: (arviz 0.11.2 (/opt/miniconda3/envs/stats_env/lib/python3.10/site-packages), Requirement.parse('arviz>=0.13.0'), {'pymc'})"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model_coal:\n",
    "    # mu_ = pmb.BART(\"μ_\", X=x_data, Y=np.log(y_data), m=20)\n",
    "    mu_ = pmb.BART(\"μ_\", X=x_data, Y=y_data, m=20)\n",
    "    mu = pm.Deterministic(\"μ\", pm.math.exp(mu_))\n",
    "    y_pred = pm.Poisson(\"y_pred\", mu=mu, observed=y_data)\n",
    "    idata_coal = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "rates = idata_coal.posterior[\"μ\"] / 4\n",
    "rate_mean = rates.mean(dim=[\"draw\", \"chain\"])\n",
    "ax.plot(x_centers, rate_mean, \"w\", lw=3)\n",
    "ax.plot(x_centers, y_data / 4, \"k.\")\n",
    "az.plot_hdi(x_centers, rates, smooth=False)\n",
    "az.plot_hdi(x_centers, rates, hdi_prob=0.5, smooth=False, plot_kwargs={\"alpha\": 0})\n",
    "ax.plot(coal, np.zeros_like(coal) - 0.5, \"k|\")\n",
    "ax.set_xlabel(\"years\")\n",
    "ax.set_ylabel(\"rate\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(x_data, rates.sel(chain=0, draw=[3, 10]).T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_trees = mu_.owner.op.all_trees\n",
    "for i in [0, 1, 2]:\n",
    "    plt.step(x_data[:, 0], [bart_trees[0][i].predict(x) for x in x_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
